# ğŸ–ï¸ Enhancing Gesture-Controlled Virtual Mouse and Keyboard Using AI Techniques

This project introduces a **gesture-controlled virtual mouse and keyboard** system using **OpenCV** and **Mediapipe**. With just your hand gestures, you can navigate your computer, type on a virtual keyboard, and even interact with a **virtual assistant** that listens to commands and performs actions.

## ğŸŒŸ Features

- **Virtual Mouse**: Control your mouse pointer, click, drag, and scroll using hand gestures.
- **Virtual Keyboard**: Type on a virtual keyboard by gesturing in the air.
- **Virtual Assistant**: Voice commands are recognized and executed, launching the required actions.

## ğŸ¯ Uses

- **Touchless Interaction**: Ideal for environments where contactless control is essential.
- **Accessibility**: Helps users with mobility impairments by offering an alternative to traditional input devices.
- **Innovation**: A stepping stone for AI-based gesture recognition systems in various applications.

## ğŸ› ï¸ Tech Stack

- **OpenCV**: For real-time computer vision tasks.
- **Mediapipe**: For hand gesture recognition.
- **Python**: Programming language used for implementation.
- **Speech Recognition**: For the virtual assistant module.

## ğŸš€ How to Use

1. **Install Dependencies**: Ensure you have all required libraries (OpenCV, Mediapipe, etc.).
2. **Run the Modules**:
   - **Virtual Mouse**: Navigate your system with hand gestures.
   - **Virtual Keyboard**: Type using gestures.
   - **Virtual Assistant**: Give voice commands, and the assistant will perform actions for you.
3. **Enjoy Touchless Control**!
